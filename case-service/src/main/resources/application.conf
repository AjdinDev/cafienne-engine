//Default application.conf runs the service based on local files out of the box.
//This is not a production setup. Please have a look in the run/case-service folder for
//a better setup with cassandra as event store and Postgres as view store.
projectionsDB = {
  profile = "slick.jdbc.H2Profile$"
  profile = ${?PROJECTION_DB_PROFILE}
  db {
    driver = "org.h2.Driver"
    driver =  ${?PROJECTION_DB_DRIVER}
    url = "jdbc:h2:file:./projections"
    url =  ${?PROJECTION_DB_URL}
    // User name to connect, update and query
    user = ""
    user =  ${?PROJECTION_DB_USER}
    password = ""
    password =  ${?PROJECTION_DB_PASSWORD}
    numThreads = 10
    connectionTimeout = 5000
    validationTimeout = 5000
  }
}

akka {
  loglevel = INFO
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logger-startup-timeout = 10s

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"

    serialize-messages = on

    serializers {
      command_serializer = "org.cafienne.akka.actor.serialization.CommandSerializer"
      response_serializer = "org.cafienne.akka.actor.serialization.ResponseSerializer"
      event_serializer = "org.cafienne.akka.actor.serialization.EventSerializer"
      // offset_serializer is used to serialize offset snapshots
      offset_serializer = "org.cafienne.infrastructure.eventstore.OffsetSerializer"
    }
    serialization-bindings {
      "org.cafienne.akka.actor.event.ModelEvent" = event_serializer
      "org.cafienne.akka.actor.command.ModelCommand" = command_serializer
      "org.cafienne.akka.actor.command.response.ModelResponse" = response_serializer
      // Current offsets are WrappedOffset objects
      "org.cafienne.infrastructure.eventstore.WrappedOffset" = offset_serializer
      // enable below to check if all events have been serialized without java.io.Serializable
      //"java.io.Serializable" = none
    }
  }

  remote {
    log-remote-lifecycle-events = on
    netty.tcp {
      hostname = "127.0.0.1"
      port = 0
    }
  }

  cluster {
    seed-nodes = ["akka://ClusterSystem@127.0.0.1:25520"]
    seed-nodes = ${?CLUSTER_SEED_NODES}

    auto-down-unreachable-after = 10s
  }

  persistence {
    journal {
      plugin = "jdbc-journal"
      auto-start-journals = ["jdbc-journal"]
    }
    snapshot-store {
      plugin = "jdbc-snapshot-store"
      // Enable the line below to automatically start the snapshot-store when the actorsystem is started
      auto-start-snapshot-stores = ["jdbc-snapshot-store"]
    }
  }

}

akka-persistence-jdbc {
  database-provider-fqcn = "org.cafienne.service.db.events.EventDatabaseProvider"
  shared-databases {
    eventdb {
      profile = "slick.jdbc.H2Profile$"
      profile = ${?EVENT_DB_PROFILE}
      db {
        connectionPool = disabled
        driver = "org.h2.Driver"
        driver =  ${?EVENT_DB_DRIVER}
        url = "jdbc:h2:file:./events"
        url =  ${?EVENT_DB_URL}
        // User name to connect, update and query
        user = ""
        user =  ${?EVENT_DB_USER}
        password = ""
        password =  ${?EVENT_DB_PASSWORD}
        numThreads = 5
        connectionTimeout = 5000
        validationTimeout = 5000
        maxConnections = 5
        minConnections = 1
      }
    }
  }

  jdbc-journal {
    use-shared-db = "eventdb"


    event-adapters {
      tagging = "org.cafienne.akka.actor.tagging.CaseTaggingEventAdapter"
    }

    event-adapter-bindings {
      "org.cafienne.akka.actor.event.ModelEvent" = tagging
    }

  }
}

# the akka-persistence-snapshot-store in use
jdbc-snapshot-store {
  use-shared-db = "eventdb"
}

# the akka-persistence-query provider in use
jdbc-read-journal {
  use-shared-db = "eventdb"
}

cafienne {
  # Platform has owners that are allowed to create/disable/enable tenants
  #  This property specifies the set of user-id's that are owners
  #  This array may not be empty.
  platform {
    owners = ["admin", "CgVhZG1pbhIFbG9jYWw"]
    owners = ${?CAFIENNE_PLATFORM_OWNERS}
    default-tenant = "world"
    default-tenant = ${?CAFIENNE_PLATFORM_DEFAULT_TENANT}
  }

  debug = false

  api {
    bindhost = "localhost"
    bindport = 2027

    security {
      # configuration settings for OpenID Connect
      oidc {
        connect-url = "http://localhost:5556/dex/.well-known/openid-configuration"
        connect-url = ${?CAFIENNE_OIDC_CONNECT_URL}
        token-url = "http://127.0.0.1:5556/dex/token"
        token-url = ${?CAFIENNE_OIDC_TOKEN_URL}
        key-url = "http://127.0.0.1:5556/dex/keys"
        key-url = ${?CAFIENNE_OIDC_KEY_URL}
        authorization-url = "http://127.0.0.1:5556/dex/auth"
        authorization-url = ${?CAFIENNE_OIDC_AUTHORIZATION_URL}
        issuer = "http://localhost:28080/dex"
        issuer = ${?CAFIENNE_OIDC_ISSUER}
      }

      # Fill this setting to true to allow developers to access
      # engine events without authentication
      debug.events.open = false
      debug.events.open = ${?CAFIENNE_DEBUG_EVENTS}
    }
  }

  # The case engine reads definitions as XML files from disk and/or the classpath.
  # The files are cached in-memory, based on their lastModified timestamp
  # (i.e., if you change a file on disk, the engine will reload it into the cache).
  # By default, the engine will read from the configured location. If the definitions file cannot be found
  # in this location, the engine will try to load it as a resource from the classpath, hence enabling to ship
  # fixed definitions in a jar file.
  definitions {
    provider = "org.cafienne.cmmn.repository.file.FileBasedDefinitionProvider"
    location = "./definitions"
    location =  ${?CAFIENNE_CMMN_DEFINITIONS_PATH}
    cache {
      size = 100
    }
  }

  actor {
    # the seconds of idle time after which a case actor is removed from akka memory
    # if the case has not received new commands after the specified number of seconds,
    # the case engine will ask akka to remove the case from memory to avoid memory leaks.
    idle-period = 600
  }
}
