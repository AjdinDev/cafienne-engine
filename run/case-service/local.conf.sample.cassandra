include "application"

projectionsDB = {
  profile = "slick.jdbc.PostgresProfile$"
  db {
    driver = org.postgresql.Driver
    url = "jdbc:postgresql://localhost:5432/postgresuser"
    user = "postgresuser"
    password = "mysecret"
    migrateUser = "postgresuser"
    migratePwd = "mysecret"
    numThreads = 10
    connectionTimeout = 5000
    validationTimeout = 5000
  }
}

akka {
  loglevel = DEBUG
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logger-startup-timeout = 10s

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"

    serialize-messages = on

    serializers {
      command_serializer = "org.cafienne.akka.actor.serialization.CommandSerializer"
      response_serializer = "org.cafienne.akka.actor.serialization.ResponseSerializer"
      event_serializer = "org.cafienne.akka.actor.serialization.EventSerializer"
      // offset_serializer is used to serialize offset snapshots
      offset_serializer = "org.cafienne.infrastructure.eventstore.OffsetSerializer"
    }
    serialization-bindings {
      "org.cafienne.akka.actor.event.ModelEvent" = event_serializer
      "org.cafienne.akka.actor.command.ModelCommand" = command_serializer
      "org.cafienne.akka.actor.command.response.ModelResponse" = response_serializer
      // Current offsets are WrappedOffset objects
      "org.cafienne.infrastructure.eventstore.WrappedOffset" = offset_serializer
      // enable below to check if all events have been serialized without java.io.Serializable
      //"java.io.Serializable" = none
    }
  }

  debug {
    receive = off
    unhandled = on
  }

  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = "127.0.0.1"
      port = 0
    }
  }

  cluster {
    seed-nodes = ["akka.tcp://ClusterSystem@127.0.0.1:2551"]
    #roles = ["case-domain"]
    #DO NOT USE AUTODOWN IN PRODUCTION
    auto-down-unreachable-after = 30s
  }

  persistence {
    journal {
      # DO NOT USE LEVELDB FOR A MULTI NODE SETUP !!!
      # NOTE: Default journal is leveldb, as it comes out of the box without setup.
      # However, this cannot be used in production or in a multi-node setup.
      # In that case, the cassandra-journal has to be enabled.
      #plugin = "akka.persistence.journal.leveldb"
      plugin = "cassandra-journal"

      # Default configuration for leveldb storage of events.
      # Cassandra configuration is at the end of this file
    }

    snapshot-store {
      # Path to the snapshot store plugin to be used
      plugin = cassandra-snapshot-store
    }
  }

}

cafienne {
  # Platform has owners that are allowed to create/disable/enable tenants
  #  This property specifies the set of user-id's that are owners
  #  This array may not be empty.
  platform {
    owners = ["admin"]
  }

  api {
    bindhost = "localhost"
    bindport = 2027

    security {
      # configuration settings for OpenID Connect
      oidc {
        connect-url = "http://localhost:5556/dex/.well-known/openid-configuration"
        token-url = "http://127.0.0.1:5556/dex/token"
        key-url = "http://127.0.0.1:5556/dex/keys"
        authorization-url = "http://127.0.0.1:5556/dex/auth"
        issuer = "http://localhost:28080/dex"
      }
    }
  }

  # The case engine reads definitions as XML files from disk and/or the classpath.
  # The files are cached in-memory, based on their lastModified timestamp
  # (i.e., if you change a file on disk, the engine will reload it into the cache).
  # By default, the engine will read from the configured location. If the definitions file cannot be found
  # in this location, the engine will try to load it as a resource from the classpath, hence enabling to ship
  # fixed definitions in a jar file.
  definitions {
    provider = "org.cafienne.cmmn.repository.file.FileBasedDefinitionProvider"
    location = "./definitions"
    cache {
      size = 100
    }
  }
}

cassandra-journal {
  keyspace-autocreate = true
  tables-autocreate = true

  event-adapters {
    tagging = "org.cafienne.akka.actor.tagging.CaseTaggingEventAdapter"
  }

  event-adapter-bindings {
    "org.cafienne.akka.actor.event.ModelEvent" = tagging
  }

}
